name: Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run integration tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHONUNBUFFERED: 1
  POETRY_NO_INTERACTION: 1
  POETRY_VENV_IN_PROJECT: 1
  
jobs:
  api-integration:
    runs-on: ubuntu-latest
    
    services:
      typesense:
        image: typesense/typesense:0.25.1
        env:
          TYPESENSE_DATA_DIR: /data
          TYPESENSE_API_KEY: test-integration-key
        ports:
          - 8108:8108
        options: >-
          --health-cmd "curl -f http://localhost:8108/health"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 3
          
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_retail_dwh
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true
        
    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v4
      with:
        path: .venv
        key: venv-integration-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}
        
    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --with dev
      
    - name: Install project
      run: poetry install --no-interaction --with dev
      
    - name: Create test directories
      run: |
        mkdir -p data/{raw,bronze,silver,gold,warehouse} logs reports/{data_quality,airflow_pipeline}
        mkdir -p backups/supabase
        
    - name: Setup test environment
      run: |
        cat > .env.integration << EOF
        ENVIRONMENT=integration
        DATABASE_TYPE=postgresql
        DATABASE_URL=postgresql://test_user:test_password@localhost:5432/test_retail_dwh
        SUPABASE_URL=http://localhost:5432
        SUPABASE_KEY=test-key
        SUPABASE_SERVICE_KEY=test-service-key
        SUPABASE_SCHEMA=retail_dwh
        API_HOST=0.0.0.0
        API_PORT=8001
        TYPESENSE_API_KEY=test-integration-key
        TYPESENSE_HOST=localhost
        TYPESENSE_PORT=8108
        ENABLE_EXTERNAL_ENRICHMENT=false
        ENABLE_VECTOR_SEARCH=true
        SECRET_KEY=test-secret-key-for-integration-tests
        BASIC_AUTH_USERNAME=test_admin
        BASIC_AUTH_PASSWORD=test_password123
        BRONZE_PATH=./data/bronze
        SILVER_PATH=./data/silver
        GOLD_PATH=./data/gold
        RAW_DATA_PATH=./data/raw
        EOF
        
    - name: Create sample test data
      run: |
        cat > data/raw/test_retail.csv << EOF
        invoice_no,stock_code,description,quantity,unit_price,invoice_timestamp,customer_id,country
        TEST-001,PROD-001,Test Product A,5,15.99,2024-01-15T10:30:00,CUST-001,United Kingdom
        TEST-001,PROD-002,Test Product B,2,25.50,2024-01-15T10:30:00,CUST-001,United Kingdom
        TEST-002,PROD-001,Test Product A,1,15.99,2024-01-15T11:00:00,CUST-002,France
        TEST-003,PROD-003,Test Product C,3,8.75,2024-01-15T12:15:00,CUST-003,Germany
        TEST-004,PROD-002,Test Product B,4,25.50,2024-01-15T14:45:00,CUST-001,United Kingdom
        EOF
        
    - name: Test core application startup
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        source .env.integration
        
        # Test core imports and configuration
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        from core.config import settings
        from api.main import app
        print(f'✅ Core application configured for {settings.environment}')
        print(f'✅ Database type: {settings.database_type}')
        print(f'✅ API configured on port {settings.api_port}')
        "
        
    - name: Test database initialization
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        source .env.integration
        
        # Test database connection and setup
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        from data_access.db import create_all, session_scope
        from core.config import settings
        
        # Create tables
        create_all()
        print('✅ Database tables created successfully')
        
        # Test session
        with session_scope() as session:
            print('✅ Database session working')
        "
        
    - name: Test Supabase integration
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        source .env.integration
        
        # Test Supabase client initialization
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        from data_access.supabase_client import get_supabase_client
        from core.config import settings
        
        try:
            client = get_supabase_client()
            print('✅ Supabase client initialized successfully')
        except Exception as e:
            print(f'⚠ Supabase client init issue (expected in test): {e}')
        "
        
    - name: Start API server
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        source .env.integration
        
        # Start API in background
        poetry run uvicorn api.main:app --host 0.0.0.0 --port 8001 &
        API_PID=$!
        
        # Wait for startup
        sleep 10
        
        # Test health endpoint
        curl -f http://localhost:8001/api/v1/health
        
        # Test authenticated endpoints
        curl -f -u test_admin:test_password123 http://localhost:8001/api/v1/sales
        
        # Test Supabase endpoints (these may fail but shouldn't crash)
        curl -f -u test_admin:test_password123 http://localhost:8001/api/v1/supabase/config || echo "Supabase config test completed"
        
        # Stop API server
        kill $API_PID
        
        echo "✅ API integration tests completed successfully"
        
    - name: Test ETL pipeline components
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        source .env.integration
        
        # Test basic ETL functionality
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        import pandas as pd
        from pathlib import Path
        
        # Read test data
        df = pd.read_csv('data/raw/test_retail.csv')
        print(f'✅ Test data loaded: {len(df)} records')
        
        # Basic processing
        df['total'] = df['quantity'] * df['unit_price']
        print(f'✅ Basic ETL processing: Total sales {df[\"total\"].sum():.2f}')
        
        # Save processed data
        bronze_path = Path('./data/bronze')
        bronze_path.mkdir(exist_ok=True)
        
        output_file = bronze_path / 'test_processed.parquet'
        df.to_parquet(output_file, index=False)
        print(f'✅ Data saved to {output_file}')
        
        # Verify saved data
        df_check = pd.read_parquet(output_file)
        assert len(df_check) == len(df), 'Data integrity check failed'
        print('✅ Data integrity verified')
        "

  airflow-dag-validation:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Install Airflow and dependencies
      run: |
        pip install apache-airflow==2.7.0
        pip install pandas sqlalchemy psycopg2-binary
        
    - name: Setup Airflow environment
      run: |
        export AIRFLOW_HOME=/tmp/airflow
        export PYTHONPATH=src:$PYTHONPATH
        
        # Initialize Airflow database
        mkdir -p $AIRFLOW_HOME
        airflow db init
        
        # Create test configuration
        mkdir -p data/{raw,bronze,silver,gold} logs
        
    - name: Test DAG imports and parsing
      run: |
        export AIRFLOW_HOME=/tmp/airflow
        export PYTHONPATH=src:$PYTHONPATH
        
        # Test DAG syntax
        python -m py_compile src/airflow_dags/retail_etl_dag.py
        python -m py_compile src/airflow_dags/advanced_retail_etl_dag.py
        python -m py_compile src/airflow_dags/airflow_config.py
        
        echo "✅ All DAGs compiled successfully"
        
        # Test DAG loading (may have import issues but shouldn't crash)
        python -c "
        import sys
        sys.path.insert(0, 'src')
        
        try:
            from airflow_dags.airflow_config import AirflowConfig, validate_dag_dependencies
            config = AirflowConfig()
            print('✅ Airflow configuration loaded')
            
            validation = validate_dag_dependencies()
            print(f'✅ DAG dependencies validation completed')
        except Exception as e:
            print(f'⚠ DAG validation issue (expected in CI): {e}')
        " || echo "DAG validation completed with warnings (expected)"

  data-quality-tests:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      
    - name: Install dependencies
      run: poetry install --no-interaction --with dev
      
    - name: Create test data with quality issues
      run: |
        mkdir -p data/raw
        
        # Create data with various quality issues
        cat > data/raw/quality_test.csv << EOF
        invoice_no,stock_code,description,quantity,unit_price,customer_id,country
        GOOD-001,PROD-001,Good Product,5,15.99,CUST-001,United Kingdom
        BAD-001,,Missing Stock Code,3,10.50,CUST-002,France
        BAD-002,PROD-003,Bad Quantity,-1,20.00,CUST-003,Germany
        BAD-003,PROD-004,Zero Price,2,0.00,CUST-004,Spain
        ,PROD-005,Missing Invoice,1,5.99,,Unknown
        GOOD-002,PROD-006,Another Good Product,4,8.75,CUST-005,Italy
        EOF
        
    - name: Test data quality validation
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        import pandas as pd
        
        # Load test data
        df = pd.read_csv('data/raw/quality_test.csv')
        print(f'✅ Test data loaded: {len(df)} records')
        
        # Quality checks
        quality_report = {}
        
        # Completeness checks
        for column in df.columns:
            null_percentage = (df[column].isnull().sum() / len(df)) * 100
            quality_report[f'{column}_completeness'] = 100 - null_percentage
        
        # Validity checks
        negative_quantities = (df['quantity'] < 0).sum() if 'quantity' in df.columns else 0
        zero_prices = (df['unit_price'] <= 0).sum() if 'unit_price' in df.columns else 0
        
        # Calculate overall quality score
        completeness_avg = sum(quality_report.values()) / len(quality_report)
        validity_score = 100 - ((negative_quantities + zero_prices) / len(df)) * 100
        
        overall_score = (completeness_avg + validity_score) / 2
        
        print(f'✅ Data quality assessment completed')
        print(f'   - Completeness: {completeness_avg:.1f}%')
        print(f'   - Validity: {validity_score:.1f}%') 
        print(f'   - Overall Score: {overall_score:.1f}%')
        print(f'   - Quality Issues Found: {negative_quantities + zero_prices}')
        
        # Should detect quality issues
        assert overall_score < 85, 'Quality test should detect issues'
        print('✅ Quality validation correctly identified issues')
        "

  performance-tests:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      
    - name: Install dependencies
      run: poetry install --no-interaction --with dev
      
    - name: Generate large test dataset
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        
        # Generate larger dataset for performance testing
        poetry run python -c "
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta
        
        # Generate 10,000 records for performance testing
        n_records = 10000
        
        # Generate synthetic data
        np.random.seed(42)
        
        data = {
            'invoice_no': [f'INV-{i:06d}' for i in range(1, n_records + 1)],
            'stock_code': [f'PROD-{np.random.randint(1, 1000):03d}' for _ in range(n_records)],
            'description': [f'Product Description {i}' for i in range(n_records)],
            'quantity': np.random.randint(1, 10, n_records),
            'unit_price': np.round(np.random.uniform(1.0, 100.0, n_records), 2),
            'customer_id': [f'CUST-{np.random.randint(1, 1000):04d}' for _ in range(n_records)],
            'country': np.random.choice(['United Kingdom', 'France', 'Germany', 'Spain', 'Italy'], n_records)
        }
        
        df = pd.DataFrame(data)
        df['invoice_timestamp'] = pd.date_range(start='2024-01-01', periods=n_records, freq='1H')
        
        # Save test data
        df.to_csv('data/raw/performance_test.csv', index=False)
        print(f'✅ Generated {len(df)} records for performance testing')
        print(f'   - File size: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB')
        "
        
    - name: Test data processing performance
      run: |
        export PYTHONPATH=src:$PYTHONPATH
        
        poetry run python -c "
        import sys
        sys.path.insert(0, 'src')
        import pandas as pd
        import time
        from pathlib import Path
        
        # Load performance test data
        start_time = time.time()
        df = pd.read_csv('data/raw/performance_test.csv')
        load_time = time.time() - start_time
        
        print(f'✅ Data loaded in {load_time:.2f} seconds')
        print(f'   - Records: {len(df):,}')
        print(f'   - Memory usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB')
        
        # Performance test: Data transformations
        start_time = time.time()
        
        # Basic transformations
        df['total'] = df['quantity'] * df['unit_price']
        df['invoice_timestamp'] = pd.to_datetime(df['invoice_timestamp'])
        df['year'] = df['invoice_timestamp'].dt.year
        df['month'] = df['invoice_timestamp'].dt.month
        
        # Aggregations
        country_summary = df.groupby('country').agg({
            'total': ['sum', 'mean', 'count'],
            'quantity': 'sum'
        })
        
        monthly_summary = df.groupby(['year', 'month']).agg({
            'total': 'sum',
            'invoice_no': 'nunique'
        })
        
        transform_time = time.time() - start_time
        
        print(f'✅ Data transformation completed in {transform_time:.2f} seconds')
        print(f'   - Countries: {len(country_summary)}')
        print(f'   - Monthly periods: {len(monthly_summary)}')
        
        # Performance test: File I/O
        start_time = time.time()
        
        bronze_path = Path('./data/bronze')
        bronze_path.mkdir(exist_ok=True)
        
        output_file = bronze_path / 'performance_test.parquet'
        df.to_parquet(output_file, index=False)
        
        io_time = time.time() - start_time
        
        print(f'✅ Data saved in {io_time:.2f} seconds')
        print(f'   - Output file size: {output_file.stat().st_size / 1024 / 1024:.2f} MB')
        
        # Verify performance thresholds
        assert load_time < 10, f'Data loading too slow: {load_time:.2f}s'
        assert transform_time < 15, f'Data transformation too slow: {transform_time:.2f}s'  
        assert io_time < 5, f'Data I/O too slow: {io_time:.2f}s'
        
        print('✅ All performance tests passed')
        "

  integration-summary:
    runs-on: ubuntu-latest
    needs: [api-integration, airflow-dag-validation, data-quality-tests, performance-tests]
    if: always()
    
    steps:
    - name: Create integration test summary
      run: |
        echo "## Integration Test Results" >> $GITHUB_STEP_SUMMARY
        echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| API Integration | ${{ needs.api-integration.result == 'success' && '✅ PASSED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Airflow DAG Validation | ${{ needs.airflow-dag-validation.result == 'success' && '✅ PASSED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Data Quality Tests | ${{ needs.data-quality-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Tests | ${{ needs.performance-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.api-integration.result }}" == "success" && 
              "${{ needs.airflow-dag-validation.result }}" == "success" && 
              "${{ needs.data-quality-tests.result }}" == "success" && 
              "${{ needs.performance-tests.result }}" == "success" ]]; then
          echo "## 🎉 All Integration Tests Passed!" >> $GITHUB_STEP_SUMMARY
          echo "The enhanced PwC Retail ETL system is ready for deployment." >> $GITHUB_STEP_SUMMARY
        else
          echo "## ⚠️ Some Integration Tests Failed" >> $GITHUB_STEP_SUMMARY
          echo "Please review the failed tests before proceeding with deployment." >> $GITHUB_STEP_SUMMARY
        fi