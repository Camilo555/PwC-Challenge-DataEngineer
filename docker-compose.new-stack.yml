version: '3.8'

services:
  # =============================================================================
  # MESSAGE QUEUE SERVICES (RabbitMQ replacing Redis)
  # =============================================================================
  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: pwc-rabbitmq
    hostname: rabbitmq
    ports:
      - "5672:5672"      # AMQP port
      - "15672:15672"    # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
      RABBITMQ_DEFAULT_VHOST: /
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./docker/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./docker/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json
    networks:
      - pwc-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # =============================================================================
  # STREAMING SERVICES (Kafka)
  # =============================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: pwc-zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - pwc-network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: pwc-kafka
    hostname: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - pwc-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: pwc-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - pwc-network
    restart: unless-stopped

  # =============================================================================
  # SPARK CLUSTER FOR DELTA LAKE
  # =============================================================================
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: pwc-spark-master
    hostname: spark-master
    ports:
      - "8081:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_DRIVER_MEMORY=1g
      - SPARK_EXECUTOR_MEMORY=2g
    volumes:
      - ./data:/opt/data
      - ./jars:/opt/spark/jars
      - spark_logs:/opt/spark/logs
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: pwc-spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./data:/opt/data
      - ./jars:/opt/spark/jars
      - spark_logs:/opt/spark/logs
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'

  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: pwc-spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./data:/opt/data
      - ./jars:/opt/spark/jars
      - spark_logs:/opt/spark/logs
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'

  # =============================================================================
  # DATADOG AGENT FOR MONITORING
  # =============================================================================
  datadog-agent:
    image: gcr.io/datadoghq/agent:7
    container_name: pwc-datadog-agent
    hostname: datadog-agent
    environment:
      - DD_API_KEY=${DD_API_KEY:-your-datadog-api-key}
      - DD_SITE=${DD_SITE:-datadoghq.com}
      - DD_APM_ENABLED=true
      - DD_APM_NON_LOCAL_TRAFFIC=true
      - DD_LOGS_ENABLED=true
      - DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL=true
      - DD_CONTAINER_EXCLUDE_LOGS="name:datadog-agent"
      - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true
      - DD_DOGSTATSD_PORT=8125
      - DD_PROCESS_AGENT_ENABLED=true
      - DD_SYSTEM_PROBE_ENABLED=true
      - DD_RUNTIME_SECURITY_CONFIG_ENABLED=true
    ports:
      - "8125:8125/udp"  # DogStatsD
      - "8126:8126"      # APM traces
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup/:/host/sys/fs/cgroup:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./docker/datadog/conf.d:/etc/datadog-agent/conf.d:ro
      - datadog_data:/opt/datadog-agent/
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # =============================================================================
  # DATABASE SERVICES
  # =============================================================================
  postgres:
    image: postgres:15
    container_name: pwc-postgres
    hostname: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: pwc_data_warehouse
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    networks:
      - pwc-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d pwc_data_warehouse"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # =============================================================================
  # SEARCH SERVICES
  # =============================================================================
  typesense:
    image: typesense/typesense:0.25.1
    container_name: pwc-typesense
    hostname: typesense
    ports:
      - "8108:8108"
    environment:
      TYPESENSE_DATA_DIR: /data
      TYPESENSE_API_KEY: pwc-typesense-key
      TYPESENSE_ENABLE_CORS: true
    volumes:
      - typesense_data:/data
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # =============================================================================
  # MONITORING SERVICES
  # =============================================================================
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: pwc-prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - pwc-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  grafana:
    image: grafana/grafana:10.0.3
    container_name: pwc-grafana
    hostname: grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin123
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel,grafana-clock-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - pwc-network
    depends_on:
      - prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # =============================================================================
  # APPLICATION SERVICES
  # =============================================================================
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
      target: production
    container_name: pwc-api
    hostname: api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://admin:admin123@postgres:5432/pwc_data_warehouse
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=admin123
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - TYPESENSE_HOST=typesense
      - TYPESENSE_PORT=8108
      - TYPESENSE_API_KEY=pwc-typesense-key
      - DD_AGENT_HOST=datadog-agent
      - DD_TRACE_AGENT_PORT=8126
      - DD_DOGSTATSD_PORT=8125
      - DD_SERVICE=pwc-data-engineering-api
      - DD_ENV=production
      - DD_VERSION=1.0.0
      - ENVIRONMENT=production
      - PROCESSING_ENGINE=spark
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - pwc-network
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      kafka:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  etl-processor:
    build:
      context: .
      dockerfile: docker/Dockerfile.etl
      target: production
    container_name: pwc-etl-processor
    hostname: etl-processor
    environment:
      - DATABASE_URL=postgresql://admin:admin123@postgres:5432/pwc_data_warehouse
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=admin123
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - DD_AGENT_HOST=datadog-agent
      - DD_TRACE_AGENT_PORT=8126
      - DD_DOGSTATSD_PORT=8125
      - DD_SERVICE=pwc-data-engineering-etl
      - DD_ENV=production
      - DD_VERSION=1.0.0
      - ENVIRONMENT=production
      - PROCESSING_ENGINE=spark
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DRIVER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=2g
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./delta_lake:/app/delta_lake
    networks:
      - pwc-network
    depends_on:
      - spark-master
      - postgres
      - rabbitmq
      - kafka
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'

  # =============================================================================
  # DAGSTER ORCHESTRATION
  # =============================================================================
  dagster:
    build:
      context: .
      dockerfile: docker/Dockerfile.dagster
    container_name: pwc-dagster
    hostname: dagster
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://admin:admin123@postgres:5432/pwc_data_warehouse
      - RABBITMQ_HOST=rabbitmq
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SPARK_MASTER_URL=spark://spark-master:7077
      - DD_AGENT_HOST=datadog-agent
      - DD_SERVICE=pwc-data-engineering-dagster
      - DD_ENV=production
      - ENVIRONMENT=production
      - PROCESSING_ENGINE=spark
    volumes:
      - ./data:/app/data
      - ./delta_lake:/app/delta_lake
      - dagster_home:/app/dagster_home
    networks:
      - pwc-network
    depends_on:
      - postgres
      - spark-master
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # =============================================================================
  # LOAD BALANCER
  # =============================================================================
  nginx:
    image: nginx:1.24-alpine
    container_name: pwc-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./docker/nginx/conf.d:/etc/nginx/conf.d
      - ./docker/ssl:/etc/ssl/certs
      - nginx_logs:/var/log/nginx
    networks:
      - pwc-network
    depends_on:
      - api
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  pwc-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  # Message Queue
  rabbitmq_data:
    driver: local
  
  # Streaming
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  
  # Database
  postgres_data:
    driver: local
  
  # Search
  typesense_data:
    driver: local
  
  # Spark
  spark_logs:
    driver: local
  
  # Monitoring
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  datadog_data:
    driver: local
  
  # Orchestration
  dagster_home:
    driver: local
  
  # Load Balancer
  nginx_logs:
    driver: local

# =============================================================================
# PROFILES FOR DIFFERENT DEPLOYMENTS
# =============================================================================
# Usage:
# docker-compose -f docker-compose.new-stack.yml --profile minimal up -d
# docker-compose -f docker-compose.new-stack.yml --profile full-stack up -d
# docker-compose -f docker-compose.new-stack.yml --profile development up -d
# docker-compose -f docker-compose.new-stack.yml --profile production up -d