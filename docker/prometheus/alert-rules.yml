groups:
  # =============================================
  # ENHANCED INFRASTRUCTURE MONITORING
  # Intelligent alerting with severity escalation
  # =============================================
  - name: infrastructure-enhanced.rules
    interval: 30s
    rules:
      # =============================================
      # CPU MONITORING - Multi-tier severity
      # =============================================
      
      # CPU Warning Level (75%+)
      - alert: CPUUsageWarning
        expr: (100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
          component: infrastructure
          resource: cpu
          tier: "75-percent"
          escalation: "team-lead"
        annotations:
          summary: "CPU usage elevated on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }} - monitoring closely"
          business_impact: "Performance may be affected if trend continues"
          action_required: "Monitor CPU-intensive processes, prepare scaling if needed"
          runbook_url: "https://runbooks.pwc.com/cpu-warning"
          
      # CPU High Level (85%+)
      - alert: CPUUsageHigh
        expr: (100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 85
        for: 2m
        labels:
          severity: error
          component: infrastructure
          resource: cpu
          tier: "85-percent"
          escalation: "on-call-engineer"
          business_impact: "performance-degradation"
        annotations:
          summary: "HIGH CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }} - immediate attention required"
          business_impact: "$27.8M platform performance impact likely"
          action_required: "Scale resources immediately, investigate high-CPU processes"
          runbook_url: "https://runbooks.pwc.com/cpu-high"
          
      # CPU Critical Level (95%+)
      - alert: CPUUsageCritical
        expr: (100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 95
        for: 1m
        labels:
          severity: critical
          component: infrastructure
          resource: cpu
          tier: "95-percent"
          escalation: "incident-commander"
          business_impact: "critical-service-impact"
        annotations:
          summary: "CRITICAL CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }} - system overload imminent"
          business_impact: "CRITICAL - $27.8M platform at risk of failure"
          action_required: "EMERGENCY scaling, traffic redirection, incident response activation"
          runbook_url: "https://runbooks.pwc.com/cpu-critical"
          paging_required: "true"
          
      # CPU Load Average Critical
      - alert: CPULoadAverageCritical
        expr: node_load5 / on(instance) node_cpu_count > 1.5
        for: 5m
        labels:
          severity: critical
          component: infrastructure
          resource: cpu-load
          escalation: "platform-team"
        annotations:
          summary: "CRITICAL CPU load average on {{ $labels.instance }}"
          description: "5-minute load average {{ $value }} exceeds 1.5x CPU cores"
          business_impact: "System responsiveness severely degraded"
          action_required: "Immediate load balancing, process optimization"

      # =============================================
      # MEMORY MONITORING - Multi-tier severity
      # =============================================
      
      # Memory Warning Level (80%+)
      - alert: MemoryUsageWarning
        expr: ((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
          component: infrastructure
          resource: memory
          tier: "80-percent"
          escalation: "team-lead"
        annotations:
          summary: "Memory usage elevated on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }} - approaching limits"
          business_impact: "Performance degradation possible if trend continues"
          action_required: "Monitor memory-intensive processes, prepare memory scaling"
          
      # Memory High Level (90%+)
      - alert: MemoryUsageHigh
        expr: ((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes) * 100 > 90
        for: 2m
        labels:
          severity: error
          component: infrastructure
          resource: memory
          tier: "90-percent"
          escalation: "on-call-engineer"
          business_impact: "performance-degradation"
        annotations:
          summary: "HIGH memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }} - immediate action required"
          business_impact: "High risk of OOM conditions affecting $27.8M platform"
          action_required: "Scale memory immediately, investigate memory leaks"
          
      # Memory Critical Level (95%+)
      - alert: MemoryUsageCritical
        expr: ((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes) * 100 > 95
        for: 1m
        labels:
          severity: critical
          component: infrastructure
          resource: memory
          tier: "95-percent"
          escalation: "incident-commander"
          business_impact: "critical-service-impact"
        annotations:
          summary: "CRITICAL memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }} - OOM imminent"
          business_impact: "CRITICAL - System failure imminent, $27.8M platform at risk"
          action_required: "EMERGENCY memory scaling, process termination, incident response"
          paging_required: "true"
          
      # Swap Usage Critical
      - alert: SwapUsageCritical
        expr: ((node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) / node_memory_SwapTotal_bytes) * 100 > 50
        for: 5m
        labels:
          severity: critical
          component: infrastructure
          resource: swap
          escalation: "platform-team"
        annotations:
          summary: "CRITICAL swap usage on {{ $labels.instance }}"
          description: "Swap usage is {{ $value }}% - severe memory pressure"
          business_impact: "Severe performance degradation due to memory pressure"
          action_required: "Immediate memory scaling, application optimization"

      # =============================================
      # DISK MONITORING - Multi-tier severity
      # =============================================
      
      # Disk Warning Level (80%+)
      - alert: DiskSpaceWarning
        expr: ((node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes) / node_filesystem_size_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
          component: infrastructure
          resource: disk
          tier: "80-percent"
          escalation: "team-lead"
        annotations:
          summary: "Disk space elevated on {{ $labels.instance }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.mountpoint }} - monitoring closely"
          business_impact: "Storage capacity approaching limits"
          action_required: "Plan storage expansion, cleanup unnecessary files"
          
      # Disk High Level (90%+)
      - alert: DiskSpaceHigh
        expr: ((node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes) / node_filesystem_size_bytes) * 100 > 90
        for: 2m
        labels:
          severity: error
          component: infrastructure
          resource: disk
          tier: "90-percent"
          escalation: "on-call-engineer"
          business_impact: "storage-impact"
        annotations:
          summary: "HIGH disk usage on {{ $labels.instance }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.mountpoint }} - immediate attention needed"
          business_impact: "Risk of write failures affecting $27.8M platform operations"
          action_required: "Expand storage immediately, cleanup large files"
          
      # Disk Critical Level (95%+)
      - alert: DiskSpaceCritical
        expr: ((node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes) / node_filesystem_size_bytes) * 100 > 95
        for: 1m
        labels:
          severity: critical
          component: infrastructure
          resource: disk
          tier: "95-percent"
          escalation: "incident-commander"
          business_impact: "critical-service-impact"
        annotations:
          summary: "CRITICAL disk space on {{ $labels.instance }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.mountpoint }} - write failures imminent"
          business_impact: "CRITICAL - Write failures imminent, $27.8M platform data at risk"
          action_required: "EMERGENCY storage expansion, immediate cleanup, incident response"
          paging_required: "true"
          
      # Disk I/O Saturation
      - alert: DiskIOSaturation
        expr: rate(node_disk_io_time_seconds_total[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          resource: disk-io
          escalation: "performance-team"
        annotations:
          summary: "Disk I/O saturation on {{ $labels.instance }}"
          description: "Disk I/O utilization {{ $value }} exceeding 80% for 10+ minutes"
          business_impact: "Storage performance degradation affecting applications"
          action_required: "Investigate I/O bottlenecks, consider storage optimization"

      # =============================================
      # NETWORK MONITORING - Multi-tier severity
      # =============================================
      
      # Network Error Rate High
      - alert: NetworkErrorRateHigh
        expr: (
          rate(node_network_receive_errs_total[5m]) + 
          rate(node_network_transmit_errs_total[5m])
        ) / (
          rate(node_network_receive_packets_total[5m]) + 
          rate(node_network_transmit_packets_total[5m])
        ) > 0.01
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          resource: network
          escalation: "network-team"
        annotations:
          summary: "High network error rate on {{ $labels.instance }}"
          description: "Network error rate {{ $value }} exceeding 1% for 10+ minutes"
          business_impact: "Network reliability degraded, connection issues possible"
          action_required: "Investigate network interface issues, check cable connections"
          
      # Network Drops Critical
      - alert: NetworkDropsCritical
        expr: (
          rate(node_network_receive_drop_total[5m]) + 
          rate(node_network_transmit_drop_total[5m])
        ) > 1000
        for: 5m
        labels:
          severity: error
          component: infrastructure
          resource: network
          escalation: "on-call-engineer"
        annotations:
          summary: "Critical network packet drops on {{ $labels.instance }}"
          description: "Network dropping {{ $value }} packets/sec - significant packet loss"
          business_impact: "High packet loss affecting application performance"
          action_required: "Immediate network diagnostics, traffic analysis"

  # =============================================
  # ENHANCED APPLICATION MONITORING
  # =============================================
  - name: application-enhanced.rules
    interval: 15s
    rules:
      # =============================================
      # CRITICAL <15ms SLA MONITORING - Enhanced
      # =============================================
      
      # 15ms SLA Warning (12ms+)
      - alert: API15msSLAWarning
        expr: histogram_quantile(0.95, rate(api_response_time_ms_bucket[5m])) > 12
        for: 3m
        labels:
          severity: warning
          component: api-performance
          sla_type: "15ms_warning"
          business_impact: "2.1M"
          escalation: "performance-team"
        annotations:
          summary: "WARNING: API approaching 15ms SLA limit"
          description: "95th percentile API response time {{ $value }}ms approaching 15ms SLA"
          business_impact: "$2.1M API story at risk - proactive optimization needed"
          action_required: "Optimize slow endpoints, review caching strategy"
          runbook_url: "https://runbooks.pwc.com/15ms-sla-warning"
          
      # 15ms SLA Violation Critical
      - alert: API15msSLAViolationCritical
        expr: histogram_quantile(0.95, rate(api_response_time_ms_bucket[5m])) > 15
        for: 1m
        labels:
          severity: critical
          component: api-performance
          sla_type: "15ms_critical"
          business_impact: "2.1M"
          escalation: "incident-commander"
          paging_required: "true"
        annotations:
          summary: "CRITICAL: <15ms SLA violation - IMMEDIATE ACTION REQUIRED"
          description: "95th percentile API response time {{ $value }}ms exceeds 15ms SLA target"
          business_impact: "CRITICAL: Production SLA breach affecting $2.1M API performance story"
          action_required: "EMERGENCY API optimization, traffic routing, infrastructure scaling"
          runbook_url: "https://runbooks.pwc.com/15ms-sla-violation"
          
      # 15ms SLA Severe Violation (25ms+)
      - alert: API15msSLASevereViolation
        expr: histogram_quantile(0.95, rate(api_response_time_ms_bucket[5m])) > 25
        for: 30s
        labels:
          severity: critical
          component: api-performance
          sla_type: "15ms_severe"
          business_impact: "2.1M"
          escalation: "emergency-response"
          paging_required: "true"
        annotations:
          summary: "SEVERE: <15ms SLA severely breached - EMERGENCY RESPONSE"
          description: "95th percentile API response time {{ $value }}ms - SEVERE SLA breach"
          business_impact: "EMERGENCY: $2.1M API story in critical state - platform stability at risk"
          action_required: "EMERGENCY traffic redirection, immediate scaling, incident response activation"
          runbook_url: "https://runbooks.pwc.com/15ms-sla-emergency"

      # 15ms SLA Compliance Monitoring - Enhanced
      - alert: API15msSLAComplianceBelow98Percent
        expr: (api_sla_compliant_total / api_requests_total) * 100 < 98
        for: 2m
        labels:
          severity: warning
          component: api-performance
          sla_type: "compliance_rate_warning"
          business_impact: "2.1M"
          escalation: "performance-team"
        annotations:
          summary: "<15ms SLA compliance below optimal 98% target"
          description: "SLA compliance rate {{ $value }}% below 98% optimal target"
          business_impact: "$2.1M API story performance declining - optimization needed"
          action_required: "Review slow endpoints, optimize critical paths"
          
      - alert: API15msSLAComplianceBelow95Percent
        expr: (api_sla_compliant_total / api_requests_total) * 100 < 95
        for: 5m
        labels:
          severity: error
          component: api-performance
          sla_type: "compliance_rate_error"
          business_impact: "2.1M"
          escalation: "on-call-engineer"
        annotations:
          summary: "<15ms SLA compliance below 95% SLO target"
          description: "SLA compliance rate {{ $value }}% below 95% SLO target"
          business_impact: "$2.1M API story SLO breach - immediate action required"
          action_required: "Immediate performance optimization, infrastructure review"
          
      - alert: API15msSLAComplianceBelow90Percent
        expr: (api_sla_compliant_total / api_requests_total) * 100 < 90
        for: 3m
        labels:
          severity: critical
          component: api-performance
          sla_type: "compliance_rate_critical"
          business_impact: "2.1M"
          escalation: "incident-commander"
          paging_required: "true"
        annotations:
          summary: "CRITICAL: <15ms SLA compliance below 90% - MAJOR DEGRADATION"
          description: "SLA compliance rate {{ $value }}% - major performance degradation"
          business_impact: "CRITICAL: $2.1M API story severely compromised"
          action_required: "EMERGENCY response, immediate scaling, incident activation"

      # =============================================
      # ULTRA-FAST <5ms PERFORMANCE MONITORING
      # =============================================
      
      # Ultra-fast Target Achievement
      - alert: API5msUltraFastTargetMissed
        expr: histogram_quantile(0.50, rate(api_response_time_ms_bucket[5m])) > 5
        for: 15m
        labels:
          severity: info
          component: api-performance
          sla_type: "ultra_fast_median"
          optimization: "opportunity"
        annotations:
          summary: "Ultra-fast <5ms median target missed"
          description: "Median response time {{ $value }}ms exceeds 5ms ultra-fast target"
          business_impact: "Performance optimization opportunity - could improve competitive advantage"
          action_required: "Analyze and optimize fastest endpoints for ultra-low latency"
          
      # Ultra-fast 95th Percentile
      - alert: API5msUltraFast95thPercentileMissed
        expr: histogram_quantile(0.95, rate(api_response_time_ms_bucket[5m])) > 8
        for: 10m
        labels:
          severity: info
          component: api-performance
          sla_type: "ultra_fast_95th"
          optimization: "high-value"
        annotations:
          summary: "Ultra-fast <8ms 95th percentile target missed"
          description: "95th percentile response time {{ $value }}ms exceeds 8ms ultra-fast target"
          business_impact: "High-value optimization opportunity for premium performance tier"
          action_required: "Focus on optimizing top-tier performance for critical endpoints"

      # =============================================
      # CACHE PERFORMANCE MONITORING
      # =============================================
      
      # Cache Hit Rate Monitoring - Multi-tier
      - alert: CacheHitRateBelow98Percent
        expr: api_cache_hit_rate < 98
        for: 10m
        labels:
          severity: info
          component: cache-performance
          sla_type: "cache_efficiency_optimal"
        annotations:
          summary: "Cache hit rate below optimal 98% target"
          description: "Cache hit rate {{ $value }}% below 98% optimal target"
          business_impact: "Cache optimization opportunity identified"
          action_required: "Review cache strategy, optimize cache keys and TTL"
          
      - alert: CacheHitRateBelow95Percent
        expr: api_cache_hit_rate < 95
        for: 5m
        labels:
          severity: warning
          component: cache-performance
          sla_type: "cache_efficiency_warning"
          business_impact: "2.1M"
        annotations:
          summary: "Cache hit rate below 95% target - impacting <15ms SLA"
          description: "Cache hit rate {{ $value }}% below 95% target, impacting <15ms SLA performance"
          business_impact: "$2.1M API story at risk - cache efficiency degraded"
          action_required: "Immediate cache optimization, review cache warming strategy"
          
      - alert: CacheHitRateBelow90Percent
        expr: api_cache_hit_rate < 90
        for: 3m
        labels:
          severity: error
          component: cache-performance
          sla_type: "cache_efficiency_error"
          business_impact: "2.1M"
          escalation: "performance-team"
        annotations:
          summary: "Cache hit rate critically low - severe <15ms SLA impact"
          description: "Cache hit rate {{ $value }}% critically low - severe performance impact"
          business_impact: "$2.1M API story severely impacted by poor cache performance"
          action_required: "Emergency cache investigation, potential cache cluster issues"

      # =============================================
      # COMPREHENSIVE API MONITORING
      # =============================================
      
      # API Response Time Tiers - Enhanced
      - alert: APIResponseTimeElevated
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="api-service"}[5m])) > 0.1
        for: 5m
        labels:
          severity: info
          component: api-performance
          tier: "100ms"
        annotations:
          summary: "API response time elevated above 100ms"
          description: "95th percentile response time is {{ $value }}s for API service"
          business_impact: "Performance opportunity - still within acceptable range"
          action_required: "Monitor trend, consider optimization if sustained"
          
      - alert: APIResponseTimeHigh
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="api-service"}[5m])) > 0.5
        for: 3m
        labels:
          severity: warning
          component: api-performance
          tier: "500ms"
          escalation: "performance-team"
        annotations:
          summary: "High API response time above 500ms"
          description: "95th percentile response time is {{ $value }}s for API service"
          business_impact: "User experience degradation, performance optimization needed"
          action_required: "Investigate slow endpoints, optimize database queries"
          
      - alert: APIResponseTimeCritical
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="api-service"}[5m])) > 2.0
        for: 2m
        labels:
          severity: error
          component: api-performance
          tier: "2000ms"
          escalation: "on-call-engineer"
        annotations:
          summary: "CRITICAL API response time above 2 seconds"
          description: "95th percentile response time is {{ $value }}s for API service"
          business_impact: "Severe user experience degradation, platform reputation at risk"
          action_required: "Immediate performance investigation, emergency optimization"

      # =============================================
      # API ERROR RATE MONITORING - Enhanced
      # =============================================
      
      # API Error Rate - Multi-tier monitoring
      - alert: APIErrorRateElevated
        expr: (rate(http_requests_total{job="api-service",status=~"5.."}[5m]) / rate(http_requests_total{job="api-service"}[5m])) * 100 > 1
        for: 5m
        labels:
          severity: warning
          component: api-reliability
          tier: "1-percent"
        annotations:
          summary: "API error rate elevated above 1%"
          description: "API 5xx error rate is {{ $value }}% over the last 5 minutes"
          business_impact: "Error rate increasing, user experience impact possible"
          action_required: "Investigate error patterns, review recent deployments"
          
      - alert: APIErrorRateHigh
        expr: (rate(http_requests_total{job="api-service",status=~"5.."}[5m]) / rate(http_requests_total{job="api-service"}[5m])) * 100 > 3
        for: 2m
        labels:
          severity: error
          component: api-reliability
          tier: "3-percent"
          escalation: "development-team"
        annotations:
          summary: "HIGH API error rate above 3%"
          description: "API 5xx error rate is {{ $value }}% over the last 5 minutes"
          business_impact: "Significant user impact, service reliability compromised"
          action_required: "Immediate investigation, error analysis, potential rollback"
          
      - alert: APIErrorRateCritical
        expr: (rate(http_requests_total{job="api-service",status=~"5.."}[5m]) / rate(http_requests_total{job="api-service"}[5m])) * 100 > 5
        for: 1m
        labels:
          severity: critical
          component: api-reliability
          tier: "5-percent"
          escalation: "incident-commander"
          paging_required: "true"
        annotations:
          summary: "CRITICAL API error rate above 5%"
          description: "API 5xx error rate is {{ $value }}% over the last 5 minutes"
          business_impact: "CRITICAL: Major service degradation, $27.8M platform reliability at risk"
          action_required: "EMERGENCY incident response, immediate service recovery actions"
          
      # 4xx Error Rate Monitoring
      - alert: APIClientErrorRateHigh
        expr: (rate(http_requests_total{job="api-service",status=~"4.."}[5m]) / rate(http_requests_total{job="api-service"}[5m])) * 100 > 10
        for: 10m
        labels:
          severity: warning
          component: api-usability
          tier: "client-errors"
        annotations:
          summary: "High API client error rate (4xx)"
          description: "API 4xx error rate is {{ $value }}% over the last 5 minutes"
          business_impact: "High client error rate may indicate API usability issues"
          action_required: "Review API documentation, validate client implementations"

      # =============================================
      # SERVICE AVAILABILITY MONITORING - Enhanced
      # =============================================
      
      # Critical Service Down - Immediate Response
      - alert: CriticalServiceDown
        expr: up{job=~"api-service|postgres"} == 0
        for: 30s
        labels:
          severity: critical
          component: service-availability
          service_tier: "critical"
          escalation: "incident-commander"
          paging_required: "true"
        annotations:
          summary: "CRITICAL SERVICE DOWN: {{ $labels.job }}"
          description: "Critical service {{ $labels.job }} on {{ $labels.instance }} is DOWN"
          business_impact: "CRITICAL: Core platform services offline, $27.8M platform at risk"
          action_required: "EMERGENCY service recovery, immediate incident response activation"
          runbook_url: "https://runbooks.pwc.com/service-down-critical"
          
      # Important Service Down
      - alert: ImportantServiceDown
        expr: up{job=~"dagster|rabbitmq|kafka|typesense"} == 0
        for: 1m
        labels:
          severity: error
          component: service-availability
          service_tier: "important"
          escalation: "on-call-engineer"
        annotations:
          summary: "IMPORTANT SERVICE DOWN: {{ $labels.job }}"
          description: "Important service {{ $labels.job }} on {{ $labels.instance }} has been down for 1+ minute"
          business_impact: "Platform functionality impacted, data pipeline disruption likely"
          action_required: "Immediate service recovery, investigate root cause"
          
      # Supporting Service Down
      - alert: SupportingServiceDown
        expr: up{job=~"spark-master|spark-worker"} == 0
        for: 5m
        labels:
          severity: warning
          component: service-availability
          service_tier: "supporting"
          escalation: "team-lead"
        annotations:
          summary: "Supporting service down: {{ $labels.job }}"
          description: "Supporting service {{ $labels.job }} on {{ $labels.instance }} has been down for 5+ minutes"
          business_impact: "Non-critical service down, some features may be unavailable"
          action_required: "Schedule service recovery during next maintenance window or investigate if urgent"

      # =============================================
      # CONNECTION AND CAPACITY MONITORING
      # =============================================
      
      # Connection Pool Monitoring - Multi-tier
      - alert: HighConcurrentConnections
        expr: service_mesh_active_connections > 800
        for: 5m
        labels:
          severity: warning
          component: connection-pool
          tier: "80-percent"
        annotations:
          summary: "High concurrent connections"
          description: "{{ $labels.service }} has {{ $value }} active connections (>80% of capacity)"
          business_impact: "Connection pool utilization high, scaling may be needed"
          action_required: "Monitor connection patterns, prepare for scaling"
          
      - alert: CriticalConcurrentConnections
        expr: service_mesh_active_connections > 1000
        for: 2m
        labels:
          severity: error
          component: connection-pool
          tier: "capacity-limit"
          escalation: "platform-team"
        annotations:
          summary: "CRITICAL: Connection pool near capacity"
          description: "{{ $labels.service }} has {{ $value }} active connections (near maximum capacity)"
          business_impact: "Connection pool exhaustion imminent, new connections may be rejected"
          action_required: "Immediate connection pool scaling, investigate connection leaks"
          
      # Request Queue Depth
      - alert: HighRequestQueueDepth
        expr: http_request_queue_depth > 100
        for: 3m
        labels:
          severity: warning
          component: request-processing
          escalation: "performance-team"
        annotations:
          summary: "High request queue depth"
          description: "Request queue depth is {{ $value }} - processing backlog detected"
          business_impact: "Request processing delayed, response times may increase"
          action_required: "Scale processing capacity, optimize request handling"

  # =============================================
  # ENHANCED DATABASE MONITORING
  # =============================================
  - name: database-enhanced.rules
    interval: 30s
    rules:
      # =============================================
      # DATABASE CONNECTION MONITORING - Enhanced
      # =============================================
      
      # Connection Pool Warning
      - alert: DatabaseConnectionPoolHigh
        expr: (pg_stat_database_numbackends / pg_settings_max_connections) * 100 > 70
        for: 5m
        labels:
          severity: warning
          component: database-connections
          tier: "70-percent"
        annotations:
          summary: "Database connection pool usage elevated"
          description: "Connection pool usage is {{ $value }}% of maximum connections"
          business_impact: "Database connection pool utilization high"
          action_required: "Monitor connection usage, optimize connection pooling"
          
      # Connection Pool Error
      - alert: DatabaseConnectionPoolNearExhaustion
        expr: (pg_stat_database_numbackends / pg_settings_max_connections) * 100 > 85
        for: 2m
        labels:
          severity: error
          component: database-connections
          tier: "85-percent"
          escalation: "database-team"
        annotations:
          summary: "Database connection pool near exhaustion"
          description: "Connection pool usage is {{ $value }}% of maximum connections"
          business_impact: "Database performance degradation, connection rejections possible"
          action_required: "Immediate connection pool scaling, investigate connection leaks"
          
      # Connection Pool Critical
      - alert: DatabaseConnectionPoolCritical
        expr: (pg_stat_database_numbackends / pg_settings_max_connections) * 100 > 95
        for: 1m
        labels:
          severity: critical
          component: database-connections
          tier: "95-percent"
          escalation: "incident-commander"
          paging_required: "true"
        annotations:
          summary: "CRITICAL: Database connection pool exhausted"
          description: "Connection pool usage is {{ $value }}% - exhaustion imminent"
          business_impact: "CRITICAL: Database connections exhausted, application failures imminent"
          action_required: "EMERGENCY connection pool expansion, immediate connection cleanup"

      # =============================================
      # DATABASE PERFORMANCE MONITORING - Enhanced
      # =============================================
      
      # Slow Query Monitoring
      - alert: DatabaseSlowQueriesHigh
        expr: rate(database_slow_queries_total[5m]) > 5
        for: 3m
        labels:
          severity: warning
          component: database-performance
          query_type: "slow-queries"
        annotations:
          summary: "High rate of slow database queries"
          description: "{{ $value }} slow queries per second detected"
          business_impact: "Database performance degraded, <15ms SLA at risk"
          action_required: "Analyze slow queries, optimize indexes, review query plans"
          
      # Query Duration Critical
      - alert: DatabaseQueryDurationCritical
        expr: histogram_quantile(0.95, rate(database_query_duration_seconds_bucket[5m])) > 5.0
        for: 2m
        labels:
          severity: error
          component: database-performance
          query_type: "duration"
          escalation: "database-team"
        annotations:
          summary: "CRITICAL database query duration"
          description: "95th percentile query duration {{ $value }}s exceeding 5 second threshold"
          business_impact: "Severe database performance impact, all dependent services affected"
          action_required: "Emergency query optimization, investigate blocking operations"
          
      # Database Lock Contention
      - alert: DatabaseLockContentionHigh
        expr: rate(pg_stat_database_conflicts[5m]) > 1
        for: 3m
        labels:
          severity: warning
          component: database-locks
          escalation: "database-team"
        annotations:
          summary: "High database lock contention"
          description: "{{ $value }} database conflicts per second detected"
          business_impact: "Database lock contention causing performance degradation"
          action_required: "Investigate locking queries, optimize transaction isolation"

      # =============================================
      # DATABASE REPLICATION MONITORING
      # =============================================
      
      # Replication Lag Warning
      - alert: DatabaseReplicationLagWarning
        expr: (pg_stat_replication_lag_bytes / 1024 / 1024) > 50
        for: 5m
        labels:
          severity: warning
          component: database-replication
          tier: "50mb"
        annotations:
          summary: "Database replication lag elevated"
          description: "Replication lag is {{ $value }}MB - monitoring closely"
          business_impact: "Replication lag increasing, data freshness may be affected"
          action_required: "Monitor replication performance, check network connectivity"
          
      # Replication Lag Critical
      - alert: DatabaseReplicationLagCritical
        expr: (pg_stat_replication_lag_bytes / 1024 / 1024) > 100
        for: 2m
        labels:
          severity: critical
          component: database-replication
          tier: "100mb"
          escalation: "database-team"
        annotations:
          summary: "CRITICAL: Database replication lag high"
          description: "Replication lag is {{ $value }}MB - immediate attention required"
          business_impact: "High replication lag, data consistency and disaster recovery at risk"
          action_required: "Immediate replication optimization, investigate network issues"
          
      # Replica Down
      - alert: DatabaseReplicaDown
        expr: pg_stat_replication_state == 0
        for: 1m
        labels:
          severity: critical
          component: database-replication
          escalation: "database-team"
          paging_required: "true"
        annotations:
          summary: "CRITICAL: Database replica is down"
          description: "Database replica {{ $labels.replica_name }} is not responding"
          business_impact: "CRITICAL: Database redundancy lost, disaster recovery compromised"
          action_required: "EMERGENCY replica recovery, investigate replica health"

      # =============================================
      # REDIS CACHE MONITORING - Enhanced
      # =============================================
      
      # Redis Memory Monitoring - Multi-tier
      - alert: RedisMemoryWarning
        expr: (redis_memory_used_bytes / redis_config_maxmemory) * 100 > 75
        for: 5m
        labels:
          severity: warning
          component: cache-memory
          tier: "75-percent"
        annotations:
          summary: "Redis memory usage elevated"
          description: "Redis memory usage is {{ $value }}% - approaching limits"
          business_impact: "Cache performance may degrade if memory continues to increase"
          action_required: "Monitor cache usage patterns, consider memory optimization"
          
      - alert: RedisMemoryHigh
        expr: (redis_memory_used_bytes / redis_config_maxmemory) * 100 > 85
        for: 2m
        labels:
          severity: error
          component: cache-memory
          tier: "85-percent"
          escalation: "cache-team"
        annotations:
          summary: "HIGH Redis memory usage"
          description: "Redis memory usage is {{ $value }}% - immediate attention needed"
          business_impact: "High cache memory usage affecting <15ms SLA performance"
          action_required: "Immediate memory optimization, review cache eviction policies"
          
      - alert: RedisMemoryCritical
        expr: (redis_memory_used_bytes / redis_config_maxmemory) * 100 > 95
        for: 1m
        labels:
          severity: critical
          component: cache-memory
          tier: "95-percent"
          escalation: "incident-commander"
        annotations:
          summary: "CRITICAL: Redis memory near exhaustion"
          description: "Redis memory usage is {{ $value }}% - exhaustion imminent"
          business_impact: "CRITICAL: Cache failures imminent, severe <15ms SLA impact expected"
          action_required: "EMERGENCY memory scaling, immediate cache optimization"
          
      # Redis Connection Monitoring
      - alert: RedisConnectionsHigh
        expr: redis_connected_clients > 1000
        for: 5m
        labels:
          severity: warning
          component: cache-connections
        annotations:
          summary: "High Redis connection count"
          description: "Redis has {{ $value }} active connections"
          business_impact: "High connection count may indicate connection pool issues"
          action_required: "Review connection pool configuration, investigate connection leaks"
          
      # Redis Command Latency
      - alert: RedisCommandLatencyHigh
        expr: redis_command_latency_seconds > 0.01
        for: 3m
        labels:
          severity: warning
          component: cache-performance
          escalation: "performance-team"
        annotations:
          summary: "High Redis command latency"
          description: "Redis command latency {{ $value }}s exceeding 10ms threshold"
          business_impact: "Cache latency impacting <15ms SLA performance"
          action_required: "Optimize Redis commands, review data structures"

  # =============================================
  # ENHANCED ETL PIPELINE MONITORING
  # =============================================
  - name: etl-enhanced.rules
    interval: 60s
    rules:
      # =============================================
      # ETL JOB FAILURE MONITORING - Enhanced
      # =============================================
      
      # Single ETL Job Failure
      - alert: ETLJobFailureSingle
        expr: increase(dagster_job_failure_total[10m]) > 0
        for: 0s
        labels:
          severity: warning
          component: etl-reliability
          failure_type: "single"
          escalation: "data-engineering"
        annotations:
          summary: "ETL job failure detected"
          description: "{{ $labels.job_name }} job failed - investigating single failure"
          business_impact: "Single ETL failure, data pipeline disruption possible"
          action_required: "Investigate job failure, check logs, retry if appropriate"
          
      # Multiple ETL Job Failures
      - alert: ETLJobFailureMultiple
        expr: increase(dagster_job_failure_total[1h]) > 2
        for: 0s
        labels:
          severity: error
          component: etl-reliability
          failure_type: "multiple"
          escalation: "data-engineering-lead"
        annotations:
          summary: "Multiple ETL job failures"
          description: "{{ $labels.job_name }} job has failed {{ $value }} times in the last hour"
          business_impact: "Multiple failures indicate systematic issue, data quality at risk"
          action_required: "Immediate investigation, check infrastructure, review recent changes"
          
      # Critical ETL Job Failure Pattern
      - alert: ETLJobFailurePattern
        expr: increase(dagster_job_failure_total[6h]) > 5
        for: 0s
        labels:
          severity: critical
          component: etl-reliability
          failure_type: "pattern"
          escalation: "incident-commander"
          business_impact: "1.8M"
        annotations:
          summary: "CRITICAL: ETL job failure pattern detected"
          description: "{{ $labels.job_name }} job has failed {{ $value }} times in 6 hours - critical pattern"
          business_impact: "CRITICAL: $1.8M Data Quality story at risk - systematic ETL failures"
          action_required: "EMERGENCY ETL investigation, data pipeline recovery, incident response"

      # =============================================
      # ETL PERFORMANCE MONITORING - Enhanced
      # =============================================
      
      # ETL Job Duration - Multi-tier
      - alert: ETLJobDurationElevated
        expr: dagster_job_duration_seconds > 1800  # 30 minutes
        for: 0s
        labels:
          severity: info
          component: etl-performance
          duration_tier: "30min"
        annotations:
          summary: "ETL job duration elevated"
          description: "{{ $labels.job_name }} running for {{ $value | humanizeDuration }} - longer than typical"
          business_impact: "Extended processing time, data freshness may be affected"
          action_required: "Monitor job progress, investigate if pattern continues"
          
      - alert: ETLJobDurationLong
        expr: dagster_job_duration_seconds > 3600  # 1 hour
        for: 0s
        labels:
          severity: warning
          component: etl-performance
          duration_tier: "1hour"
          escalation: "data-engineering"
        annotations:
          summary: "ETL job running longer than expected"
          description: "{{ $labels.job_name }} has been running for {{ $value | humanizeDuration }}"
          business_impact: "Extended processing affecting data pipeline SLAs"
          action_required: "Investigate job performance, consider optimization or scaling"
          
      - alert: ETLJobDurationCritical
        expr: dagster_job_duration_seconds > 7200  # 2 hours
        for: 0s
        labels:
          severity: error
          component: etl-performance
          duration_tier: "2hours"
          escalation: "data-engineering-lead"
        annotations:
          summary: "CRITICAL ETL job duration"
          description: "{{ $labels.job_name }} has been running for {{ $value | humanizeDuration }} - critical duration"
          business_impact: "Critical processing delay, data freshness SLA breach likely"
          action_required: "Immediate investigation, consider job termination and restart"
          
      # ETL Throughput Monitoring
      - alert: ETLThroughputDegraded
        expr: etl_throughput_records_per_second < 100
        for: 10m
        labels:
          severity: warning
          component: etl-performance
          performance: "throughput"
        annotations:
          summary: "ETL throughput degraded"
          description: "{{ $labels.job_name }} processing only {{ $value }} records/second"
          business_impact: "ETL processing slower than expected, data pipeline efficiency reduced"
          action_required: "Investigate performance bottlenecks, optimize data processing"

      # =============================================
      # DATA QUALITY MONITORING - Enhanced
      # =============================================
      
      # Data Quality Issue Tiers
      - alert: DataQualityIssuesEmerging
        expr: increase(data_quality_issues_total[1h]) > 5
        for: 0s
        labels:
          severity: info
          component: data-quality
          issue_tier: "emerging"
        annotations:
          summary: "Data quality issues emerging"
          description: "{{ $value }} data quality issues detected in the last hour - monitoring trend"
          business_impact: "Data quality concerns emerging, monitoring required"
          action_required: "Review data quality patterns, investigate potential causes"
          
      - alert: DataQualityIssuesElevated
        expr: increase(data_quality_issues_total[1h]) > 10
        for: 0s
        labels:
          severity: warning
          component: data-quality
          issue_tier: "elevated"
          business_impact: "1.8M"
        annotations:
          summary: "Data quality issues elevated"
          description: "{{ $value }} data quality issues detected in the last hour"
          business_impact: "$1.8M Data Quality story at risk - elevated issue count"
          action_required: "Investigate data quality rules, validate data sources"
          
      - alert: DataQualityIssuesCritical
        expr: increase(data_quality_issues_total[1h]) > 25
        for: 0s
        labels:
          severity: critical
          component: data-quality
          issue_tier: "critical"
          escalation: "data-engineering-lead"
          business_impact: "1.8M"
        annotations:
          summary: "CRITICAL: High data quality issue count"
          description: "{{ $value }} data quality issues detected in the last hour - critical threshold breached"
          business_impact: "CRITICAL: $1.8M Data Quality story severely compromised"
          action_required: "EMERGENCY data quality investigation, data pipeline review"
          
      # Data Quality Score Monitoring
      - alert: DataQualityScoreLow
        expr: etl_data_quality_score_percentage < 90
        for: 5m
        labels:
          severity: warning
          component: data-quality-score
          business_impact: "1.8M"
        annotations:
          summary: "Data quality score below target"
          description: "Data quality score {{ $value }}% below 90% target for {{ $labels.job_name }}"
          business_impact: "$1.8M Data Quality story performance declining"
          action_required: "Investigate quality issues, optimize validation rules"
          
      - alert: DataQualityScoreCritical
        expr: etl_data_quality_score_percentage < 80
        for: 2m
        labels:
          severity: critical
          component: data-quality-score
          escalation: "data-engineering-lead"
          business_impact: "1.8M"
        annotations:
          summary: "CRITICAL: Data quality score severely degraded"
          description: "Data quality score {{ $value }}% critically low for {{ $labels.job_name }}"
          business_impact: "CRITICAL: $1.8M Data Quality story failing - immediate action required"
          action_required: "EMERGENCY data quality recovery, validate data integrity"

      # =============================================
      # DATA FRESHNESS MONITORING - Enhanced
      # =============================================
      
      # Data Freshness - Multi-tier monitoring
      - alert: DataFreshnessWarning
        expr: time() - data_last_updated_timestamp > 3600  # 1 hour
        for: 10m
        labels:
          severity: warning
          component: data-freshness
          freshness_tier: "1hour"
        annotations:
          summary: "Data freshness approaching limit"
          description: "Data was last updated {{ $value | humanizeDuration }} ago - approaching freshness SLA"
          business_impact: "Data freshness declining, analytics accuracy may be affected"
          action_required: "Check ETL pipeline health, investigate update delays"
          
      - alert: DataFreshnessViolation
        expr: time() - data_last_updated_timestamp > 7200  # 2 hours
        for: 5m
        labels:
          severity: error
          component: data-freshness
          freshness_tier: "2hours"
          escalation: "data-engineering"
        annotations:
          summary: "Data freshness SLA violation"
          description: "Data was last updated {{ $value | humanizeDuration }} ago - SLA breach"
          business_impact: "Data freshness SLA breached, analytics and reporting affected"
          action_required: "Immediate ETL pipeline investigation, data update recovery"
          
      - alert: DataFreshnessCritical
        expr: time() - data_last_updated_timestamp > 14400  # 4 hours
        for: 2m
        labels:
          severity: critical
          component: data-freshness
          freshness_tier: "4hours"
          escalation: "data-engineering-lead"
          business_impact: "1.8M"
        annotations:
          summary: "CRITICAL: Data severely stale"
          description: "Data was last updated {{ $value | humanizeDuration }} ago - critically stale"
          business_impact: "CRITICAL: $1.8M Data Quality story compromised - data severely outdated"
          action_required: "EMERGENCY data pipeline recovery, investigate systematic failure"

  # =============================================
  # ENHANCED BUSINESS METRICS MONITORING
  # =============================================
  - name: business-enhanced.rules
    interval: 60s
    rules:
      # Revenue Drop
      - alert: RevenueDrop
        expr: (rate(daily_revenue[1h]) / rate(daily_revenue[1h] offset 24h) - 1) * 100 < -20
        for: 30m
        labels:
          severity: critical
          component: business
        annotations:
          summary: "Significant revenue drop detected"
          description: "Revenue has dropped by {{ $value }}% compared to yesterday"

      # Transaction Volume Anomaly
      - alert: TransactionVolumeAnomaly
        expr: abs((rate(total_transactions[1h]) - rate(total_transactions[1h] offset 168h)) / rate(total_transactions[1h] offset 168h)) > 0.5
        for: 15m
        labels:
          severity: warning
          component: business
        annotations:
          summary: "Unusual transaction volume"
          description: "Transaction volume is {{ $value }}% different from last week"

      # Customer Acquisition Rate Low
      - alert: LowCustomerAcquisition
        expr: rate(new_customers_total[24h]) < 50
        for: 1h
        labels:
          severity: warning
          component: business
        annotations:
          summary: "Low customer acquisition rate"
          description: "Only {{ $value }} new customers acquired in the last 24 hours"

  - name: security.rules
    interval: 15s
    rules:
      # High Authentication Failure Rate
      - alert: HighAuthFailureRate
        expr: (rate(http_requests_total{endpoint="/api/v1/auth/login",status="401"}[5m]) / rate(http_requests_total{endpoint="/api/v1/auth/login"}[5m])) * 100 > 50
        for: 2m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "High authentication failure rate"
          description: "Authentication failure rate is {{ $value }}% - possible brute force attack"

      # Unusual API Access Patterns
      - alert: UnusualAPIAccess
        expr: rate(http_requests_total[5m]) by (remote_addr) > 100
        for: 2m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Unusual API access pattern"
          description: "High request rate from {{ $labels.remote_addr }}: {{ $value }} requests/second"

      # SSL Certificate Expiry
      - alert: SSLCertificateExpiry
        expr: (ssl_cert_not_after - time()) / 86400 < 30
        for: 1h
        labels:
          severity: warning
          component: security
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate for {{ $labels.instance }} expires in {{ $value }} days"

  - name: cost-optimization.rules
    interval: 300s  # 5 minutes
    rules:
      # Underutilized Resources
      - alert: UnderutilizedCPU
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) < 20
        for: 2h  # Must be underutilized for 2 hours
        labels:
          severity: info
          component: cost-optimization
        annotations:
          summary: "Underutilized CPU resources"
          description: "CPU usage on {{ $labels.instance }} is only {{ $value }}% - consider downsizing"

      # Unused Storage Volumes
      - alert: UnusedStorageVolume
        expr: node_filesystem_files_free / node_filesystem_files > 0.95
        for: 24h  # Volume must be mostly empty for 24 hours
        labels:
          severity: info
          component: cost-optimization
        annotations:
          summary: "Storage volume appears unused"
          description: "Volume {{ $labels.mountpoint }} on {{ $labels.instance }} is {{ $value }}% empty"

  # ML Model Monitoring Rules
  - name: ml.rules
    interval: 60s
    rules:
      # Model Drift Detection
      - alert: MLModelDriftDetected
        expr: ml_model_drift_score > 0.1
        for: 5m
        labels:
          severity: warning
          component: ml-monitoring
        annotations:
          summary: "ML model drift detected"
          description: "Model {{ $labels.model_id }} feature {{ $labels.feature_name }} drift score: {{ $value }}"
          runbook_url: "https://runbooks.example.com/ml-drift"

      # Critical Model Drift
      - alert: MLModelCriticalDrift
        expr: ml_model_drift_score > 0.2
        for: 2m
        labels:
          severity: critical
          component: ml-monitoring
        annotations:
          summary: "Critical ML model drift detected"
          description: "Model {{ $labels.model_id }} has critical drift ({{ $value }}) - immediate retraining required"

      # Model Accuracy Drop
      - alert: MLModelAccuracyDrop
        expr: ml_model_accuracy < 0.8
        for: 5m
        labels:
          severity: warning
          component: ml-monitoring
        annotations:
          summary: "ML model accuracy below threshold"
          description: "Model {{ $labels.model_id }} accuracy dropped to {{ $value }}"

      # Model Inference Errors
      - alert: MLModelInferenceErrors
        expr: (rate(ml_model_inferences_total{status="error"}[5m]) / rate(ml_model_inferences_total[5m])) * 100 > 5
        for: 2m
        labels:
          severity: critical
          component: ml-monitoring
        annotations:
          summary: "High ML model inference error rate"
          description: "Model {{ $labels.model_id }} error rate: {{ $value }}%"

      # Model Latency High
      - alert: MLModelHighLatency
        expr: histogram_quantile(0.95, rate(ml_model_inference_duration_seconds_bucket[5m])) > 2.0
        for: 5m
        labels:
          severity: warning
          component: ml-monitoring
        annotations:
          summary: "High ML model inference latency"
          description: "Model {{ $labels.model_id }} 95th percentile latency: {{ $value }}s"

  # Streaming Pipeline Rules
  - name: streaming.rules
    interval: 30s
    rules:
      # Kafka Consumer Lag
      - alert: KafkaConsumerLag
        expr: kafka_consumer_lag_sum > 1000
        for: 2m
        labels:
          severity: warning
          component: streaming
        annotations:
          summary: "Kafka consumer lag is high"
          description: "Consumer {{ $labels.consumer_group }} lag: {{ $value }} messages"

      # Stream Processing Errors
      - alert: StreamProcessingErrors
        expr: rate(stream_processing_errors_total[5m]) > 1
        for: 2m
        labels:
          severity: critical
          component: streaming
        annotations:
          summary: "Stream processing errors detected"
          description: "Stream {{ $labels.stream_name }} error rate: {{ $value }} errors/sec"

      # Real-time Data Delay
      - alert: RealtimeDataDelay
        expr: realtime_processing_delay_seconds > 30
        for: 1m
        labels:
          severity: warning
          component: streaming
        annotations:
          summary: "Real-time data processing delay"
          description: "Stream {{ $labels.stream_name }} delay: {{ $value }}s"

      # Schema Evolution Failure
      - alert: SchemaEvolutionFailure
        expr: increase(schema_evolution_failures_total[1h]) > 0
        for: 0s
        labels:
          severity: critical
          component: streaming
        annotations:
          summary: "Schema evolution failure"
          description: "Schema evolution failed for stream {{ $labels.stream_name }}"

  # Data Quality Rules
  - name: data-quality.rules
    interval: 60s
    rules:
      # Data Completeness Issues
      - alert: DataCompletenessIssue
        expr: data_completeness_percentage < 95
        for: 5m
        labels:
          severity: warning
          component: data-quality
        annotations:
          summary: "Data completeness below threshold"
          description: "Dataset {{ $labels.dataset_name }} completeness: {{ $value }}%"

      # Data Accuracy Issues
      - alert: DataAccuracyIssue
        expr: data_accuracy_score < 0.9
        for: 5m
        labels:
          severity: warning
          component: data-quality
        annotations:
          summary: "Data accuracy below threshold"
          description: "Dataset {{ $labels.dataset_name }} accuracy score: {{ $value }}"

      # Duplicate Records High
      - alert: HighDuplicateRecords
        expr: (duplicate_records_count / total_records_count) * 100 > 5
        for: 5m
        labels:
          severity: warning
          component: data-quality
        annotations:
          summary: "High duplicate record percentage"
          description: "Dataset {{ $labels.dataset_name }} has {{ $value }}% duplicate records"

      # Anomaly Detection Alert
      - alert: DataAnomalyDetected
        expr: data_anomaly_score > 0.8
        for: 2m
        labels:
          severity: warning
          component: data-quality
        annotations:
          summary: "Data anomaly detected"
          description: "Anomaly detected in {{ $labels.dataset_name }} with score {{ $value }}"

  # Advanced Security Rules
  - name: advanced-security.rules
    interval: 15s
    rules:
      # DLP Violations
      - alert: DLPViolation
        expr: increase(dlp_violations_total[5m]) > 0
        for: 0s
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Data Loss Prevention violation"
          description: "DLP violation detected: {{ $labels.violation_type }}"

      # Compliance Framework Violation
      - alert: ComplianceViolation
        expr: increase(compliance_violations_total[5m]) > 0
        for: 0s
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Compliance framework violation"
          description: "{{ $labels.framework }} compliance violation: {{ $labels.violation_details }}"

      # Zero Trust Policy Violation
      - alert: ZeroTrustPolicyViolation
        expr: increase(zero_trust_policy_violations_total[5m]) > 0
        for: 0s
        labels:
          severity: high
          component: security
        annotations:
          summary: "Zero Trust policy violation"
          description: "Zero Trust violation: {{ $labels.policy_name }}"

      # Threat Detection Alert
      - alert: ThreatDetected
        expr: increase(threats_detected_total[1m]) > 0
        for: 0s
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Security threat detected"
          description: "Threat detected: {{ $labels.threat_type }} from {{ $labels.source_ip }}"

      # Suspicious User Behavior
      - alert: SuspiciousUserBehavior
        expr: user_behavior_anomaly_score > 0.8
        for: 2m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Suspicious user behavior detected"
          description: "User {{ $labels.user_id }} behavior anomaly score: {{ $value }}"

  # Enterprise SLO Rules
  - name: slo.rules
    interval: 60s
    rules:
      # API Availability SLO
      - alert: APIAvailabilitySLOBreach
        expr: (rate(http_requests_total{status=~"2.."}[5m]) / rate(http_requests_total[5m])) * 100 < 99.5
        for: 5m
        labels:
          severity: critical
          component: slo
        annotations:
          summary: "API availability SLO breach"
          description: "API availability {{ $value }}% below 99.5% SLO"

      # ETL Processing SLO
      - alert: ETLProcessingSLOBreach
        expr: histogram_quantile(0.95, rate(etl_processing_duration_seconds_bucket[30m])) > 3600
        for: 15m
        labels:
          severity: warning
          component: slo
        annotations:
          summary: "ETL processing SLO breach"
          description: "95th percentile ETL processing time {{ $value }}s exceeds 1 hour SLO"

      # Data Freshness SLO
      - alert: DataFreshnessSLOBreach
        expr: (time() - data_last_updated_timestamp) / 3600 > 4
        for: 15m
        labels:
          severity: warning
          component: slo
        annotations:
          summary: "Data freshness SLO breach"
          description: "Data is {{ $value }} hours old, exceeding 4 hour freshness SLO"

  # Cost and Resource Optimization
  - name: advanced-cost-optimization.rules
    interval: 300s
    rules:
      # High Cloud Costs
      - alert: HighCloudCosts
        expr: daily_cloud_spend > 1000
        for: 1h
        labels:
          severity: warning
          component: cost-optimization
        annotations:
          summary: "Daily cloud costs are high"
          description: "Daily cloud spend is ${{ $value }}, exceeding budget threshold"

      # Inefficient Resource Usage
      - alert: InefficientResourceUsage
        expr: (cpu_usage_percentage < 30) and (memory_usage_percentage < 50)
        for: 4h
        labels:
          severity: info
          component: cost-optimization
        annotations:
          summary: "Inefficient resource usage detected"
          description: "Instance {{ $labels.instance }} has low utilization: CPU {{ $labels.cpu_usage_percentage }}%, Memory {{ $labels.memory_usage_percentage }}%"

      # Auto-scaling Opportunity
      - alert: AutoScalingOpportunity
        expr: (avg_over_time(cpu_usage_percentage[1h]) > 80) and (auto_scaling_enabled == 0)
        for: 30m
        labels:
          severity: info
          component: cost-optimization
        annotations:
          summary: "Auto-scaling opportunity identified"
          description: "High sustained CPU usage on {{ $labels.instance }} without auto-scaling enabled"

  # BMAD Story Monitoring Rules
  - name: bmad-stories.rules
    interval: 60s
    rules:
      # BMAD Story 1: BI Dashboards ($2.5M)
      - alert: BMADDashboardPerformanceDegradation
        expr: bmad_dashboard_load_time{story_id="1"} > 3.0
        for: 2m
        labels:
          severity: warning
          component: bi-dashboards
          story_id: "1"
          business_value: "2.5M"
        annotations:
          summary: "BI Dashboard performance degraded"
          description: "Dashboard load time {{ $value }}s exceeds 3s threshold for $2.5M BI story"
          business_impact: "Executive decision-making delayed, $2.5M business value at risk"
          runbook_url: "https://runbooks.pwc.com/bmad-story-1"

      # BMAD Story 2: Data Quality ($1.8M)
      - alert: BMADDataQualityBreach
        expr: bmad_data_quality_score{story_id="2"} < 95
        for: 5m
        labels:
          severity: critical
          component: data-quality
          story_id: "2"
          business_value: "1.8M"
        annotations:
          summary: "Data quality below acceptable threshold"
          description: "Data quality score {{ $value }}% below 95% SLO for $1.8M data quality story"
          business_impact: "Analytics accuracy compromised, $1.8M business value degraded"

      # BMAD Story 3: Security & Governance ($3.2M)
      - alert: BMADSecurityComplianceBreach
        expr: bmad_compliance_score{story_id="3"} < 98
        for: 1m
        labels:
          severity: critical
          component: security-governance
          story_id: "3"
          business_value: "3.2M"
        annotations:
          summary: "Security compliance breach detected"
          description: "Compliance score {{ $value }}% below 98% for $3.2M security story"
          business_impact: "Regulatory risk exposure, $3.2M business value threatened"

      # BMAD Story 4: API Performance ($2.1M) - Enhanced <15ms SLA Monitoring
      - alert: BMADAPIPerformanceSLOBreach
        expr: histogram_quantile(0.95, rate(bmad_api_duration_seconds_bucket{story_id="4"}[5m])) > 0.015
        for: 2m
        labels:
          severity: critical
          component: api-performance
          story_id: "4"
          business_value: "2.1M"
        annotations:
          summary: "API performance <15ms SLO breach - CRITICAL"
          description: "95th percentile API latency {{ $value }}ms exceeds 15ms SLO for $2.1M API story"
          business_impact: "Critical performance degradation, $2.1M API business value at risk"
          runbook_url: "https://runbooks.pwc.com/api-performance-15ms-sla"

      # BMAD Story 4.1: Mobile Analytics ($2.8M)
      - alert: BMADMobilePerformanceDegradation
        expr: bmad_mobile_app_launch_time{story_id="4.1"} > 3.0
        for: 1m
        labels:
          severity: warning
          component: mobile-analytics
          story_id: "4.1"
          business_value: "2.8M"
        annotations:
          summary: "Mobile app performance degraded"
          description: "Mobile app launch time {{ $value }}s exceeds 3s threshold for $2.8M mobile story"
          business_impact: "Mobile user experience compromised, $2.8M business value at risk"

      # BMAD Story 4.2: AI/LLM Analytics ($3.5M)
      - alert: BMADAIModelAccuracyDrop
        expr: bmad_ai_model_accuracy{story_id="4.2"} < 85
        for: 5m
        labels:
          severity: critical
          component: ai-llm-analytics
          story_id: "4.2"
          business_value: "3.5M"
        annotations:
          summary: "AI/LLM model accuracy below threshold"
          description: "AI model accuracy {{ $value }}% below 85% threshold for $3.5M AI story"
          business_impact: "AI-driven insights accuracy degraded, $3.5M business value compromised"

      # BMAD Story 6: Advanced Security ($4.2M)
      - alert: BMADAdvancedThreatDetected
        expr: increase(bmad_threats_detected_total{story_id="6"}[5m]) > 0
        for: 0s
        labels:
          severity: critical
          component: advanced-security
          story_id: "6"
          business_value: "4.2M"
        annotations:
          summary: "Advanced security threat detected"
          description: "Security threat detected in $4.2M advanced security system"
          business_impact: "Critical security event, $4.2M security infrastructure responding"

      # BMAD Story 7: Real-time Streaming ($3.4M)
      - alert: BMADStreamingLatencyHigh
        expr: bmad_streaming_latency_seconds{story_id="7"} > 0.1
        for: 2m
        labels:
          severity: warning
          component: streaming
          story_id: "7"
          business_value: "3.4M"
        annotations:
          summary: "Real-time streaming latency high"
          description: "Streaming latency {{ $value }}s exceeds 100ms threshold for $3.4M streaming story"
          business_impact: "Real-time analytics delayed, $3.4M streaming value degraded"

      # BMAD Story 8: ML Operations ($6.4M)
      - alert: BMADMLOpsModelDrift
        expr: bmad_ml_model_drift_score{story_id="8"} > 0.1
        for: 5m
        labels:
          severity: warning
          component: ml-operations
          story_id: "8"
          business_value: "6.4M"
        annotations:
          summary: "ML model drift detected"
          description: "ML model drift score {{ $value }} exceeds 0.1 threshold for $6.4M ML story"
          business_impact: "ML model accuracy degrading, $6.4M ML operations value at risk"

  # BMAD Platform Health Rules
  - name: bmad-platform.rules
    interval: 30s
    rules:
      # Overall Platform Health
      - alert: BMADPlatformHealthCritical
        expr: bmad_platform_health_score < 95
        for: 2m
        labels:
          severity: critical
          component: platform
          business_impact: "critical"
        annotations:
          summary: "BMAD platform health critical"
          description: "Overall platform health {{ $value }}% below 95% threshold"
          business_impact: "$27.8M+ total business value at risk due to platform degradation"

      # Total Business Value at Risk
      - alert: BMADBusinessValueAtRisk
        expr: sum(bmad_story_business_value * (1 - bmad_story_health_score/100)) > 5000000
        for: 5m
        labels:
          severity: critical
          component: business-value
        annotations:
          summary: "Significant business value at risk"
          description: "${{ $value }} million in business value at risk across BMAD stories"
          business_impact: "Multiple BMAD stories underperforming, executive attention required"

      # ROI Achievement Below Target
      - alert: BMADROIBelowTarget
        expr: bmad_overall_roi_percentage < 80
        for: 15m
        labels:
          severity: warning
          component: business-kpi
        annotations:
          summary: "BMAD ROI achievement below target"
          description: "Overall ROI achievement {{ $value }}% below 80% target"
          business_impact: "BMAD implementation not meeting expected returns"

  # Business Intelligence Rules Enhanced
  - name: business-intelligence.rules
    interval: 300s
    rules:
      # Executive Dashboard Usage
      - alert: ExecutiveDashboardLowUsage
        expr: bmad_executive_dashboard_daily_users < 10
        for: 2h
        labels:
          severity: warning
          component: business-intelligence
        annotations:
          summary: "Low executive dashboard usage"
          description: "Only {{ $value }} daily users on executive dashboards"
          business_impact: "Executive visibility into $27.8M BMAD implementation reduced"

      # KPI Threshold Breach Enhanced
      - alert: BusinessKPIThresholdBreach
        expr: business_kpi_value{kpi_name="customer_satisfaction"} < 0.8
        for: 1h
        labels:
          severity: warning
          component: business-intelligence
        annotations:
          summary: "Business KPI below threshold"
          description: "{{ $labels.kpi_name }} is {{ $value }}, below target threshold"

      # Revenue Impact Analysis
      - alert: BMADRevenueImpactNegative
        expr: bmad_revenue_impact_percentage < -5
        for: 1h
        labels:
          severity: critical
          component: business-intelligence
        annotations:
          summary: "Negative revenue impact detected"
          description: "BMAD platform showing {{ $value }}% negative revenue impact"
          business_impact: "$27.8M investment showing negative returns, immediate review required"

      # Customer Churn Rate High
      - alert: HighCustomerChurnRate
        expr: customer_churn_rate > 0.05
        for: 24h
        labels:
          severity: warning
          component: business-intelligence
        annotations:
          summary: "High customer churn rate"
          description: "Customer churn rate is {{ $value }}, above 5% threshold"